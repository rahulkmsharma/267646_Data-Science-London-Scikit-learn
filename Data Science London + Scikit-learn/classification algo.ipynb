{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_labels_df = pd.read_csv(\"trainLabels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= np.arange(40)\n",
    "train_df.columns = cols\n",
    "test_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.374101</td>\n",
       "      <td>0.537669</td>\n",
       "      <td>0.081063</td>\n",
       "      <td>0.756773</td>\n",
       "      <td>0.915231</td>\n",
       "      <td>2.557282</td>\n",
       "      <td>3.703187</td>\n",
       "      <td>1.673835</td>\n",
       "      <td>-0.764122</td>\n",
       "      <td>-1.228040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.969463</td>\n",
       "      <td>0.574154</td>\n",
       "      <td>-2.200519</td>\n",
       "      <td>-1.612240</td>\n",
       "      <td>0.179031</td>\n",
       "      <td>-2.924596</td>\n",
       "      <td>0.643610</td>\n",
       "      <td>-1.470939</td>\n",
       "      <td>-0.067408</td>\n",
       "      <td>-0.976265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.088370</td>\n",
       "      <td>0.154743</td>\n",
       "      <td>0.380716</td>\n",
       "      <td>-1.176126</td>\n",
       "      <td>1.699867</td>\n",
       "      <td>-0.258627</td>\n",
       "      <td>-1.384999</td>\n",
       "      <td>1.093584</td>\n",
       "      <td>1.596633</td>\n",
       "      <td>0.230631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769885</td>\n",
       "      <td>-0.005143</td>\n",
       "      <td>1.467490</td>\n",
       "      <td>0.483803</td>\n",
       "      <td>-3.542981</td>\n",
       "      <td>0.814561</td>\n",
       "      <td>-1.652948</td>\n",
       "      <td>1.265866</td>\n",
       "      <td>-1.749248</td>\n",
       "      <td>1.773784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.685635</td>\n",
       "      <td>0.501283</td>\n",
       "      <td>1.873375</td>\n",
       "      <td>0.215224</td>\n",
       "      <td>-3.983468</td>\n",
       "      <td>-0.103637</td>\n",
       "      <td>4.136113</td>\n",
       "      <td>-0.225431</td>\n",
       "      <td>-1.515015</td>\n",
       "      <td>-1.071763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968609</td>\n",
       "      <td>2.386412</td>\n",
       "      <td>-0.131219</td>\n",
       "      <td>0.285646</td>\n",
       "      <td>2.302069</td>\n",
       "      <td>1.255588</td>\n",
       "      <td>-1.563090</td>\n",
       "      <td>-0.125258</td>\n",
       "      <td>-1.030761</td>\n",
       "      <td>-2.945329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.350867</td>\n",
       "      <td>0.721897</td>\n",
       "      <td>-0.477104</td>\n",
       "      <td>-1.748776</td>\n",
       "      <td>-2.627405</td>\n",
       "      <td>1.075433</td>\n",
       "      <td>4.954253</td>\n",
       "      <td>-3.293501</td>\n",
       "      <td>-0.760369</td>\n",
       "      <td>0.204360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260553</td>\n",
       "      <td>-2.045650</td>\n",
       "      <td>-2.173227</td>\n",
       "      <td>0.372992</td>\n",
       "      <td>0.450700</td>\n",
       "      <td>-0.211657</td>\n",
       "      <td>1.301359</td>\n",
       "      <td>-0.522164</td>\n",
       "      <td>2.484883</td>\n",
       "      <td>0.039213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.424627</td>\n",
       "      <td>1.536196</td>\n",
       "      <td>-1.037752</td>\n",
       "      <td>-0.156466</td>\n",
       "      <td>-2.945038</td>\n",
       "      <td>-0.471607</td>\n",
       "      <td>3.494966</td>\n",
       "      <td>-2.763629</td>\n",
       "      <td>0.819540</td>\n",
       "      <td>0.209529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.727066</td>\n",
       "      <td>-0.809620</td>\n",
       "      <td>4.504230</td>\n",
       "      <td>-0.481077</td>\n",
       "      <td>-2.923646</td>\n",
       "      <td>-0.468034</td>\n",
       "      <td>-0.846214</td>\n",
       "      <td>1.197350</td>\n",
       "      <td>-5.615563</td>\n",
       "      <td>2.049134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>0.171644</td>\n",
       "      <td>-0.806952</td>\n",
       "      <td>-2.045671</td>\n",
       "      <td>0.021156</td>\n",
       "      <td>2.258491</td>\n",
       "      <td>0.429469</td>\n",
       "      <td>0.857187</td>\n",
       "      <td>0.972600</td>\n",
       "      <td>1.707492</td>\n",
       "      <td>1.676370</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.366312</td>\n",
       "      <td>0.276543</td>\n",
       "      <td>-0.732764</td>\n",
       "      <td>0.243930</td>\n",
       "      <td>-1.151233</td>\n",
       "      <td>-0.274298</td>\n",
       "      <td>0.573013</td>\n",
       "      <td>1.109814</td>\n",
       "      <td>-1.905965</td>\n",
       "      <td>1.457601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>1.168564</td>\n",
       "      <td>-0.911253</td>\n",
       "      <td>1.685492</td>\n",
       "      <td>0.867183</td>\n",
       "      <td>3.606170</td>\n",
       "      <td>-0.673875</td>\n",
       "      <td>-1.889365</td>\n",
       "      <td>0.411385</td>\n",
       "      <td>-0.206817</td>\n",
       "      <td>-0.705771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557757</td>\n",
       "      <td>0.379841</td>\n",
       "      <td>-1.474198</td>\n",
       "      <td>-0.322943</td>\n",
       "      <td>1.964519</td>\n",
       "      <td>0.122384</td>\n",
       "      <td>0.678023</td>\n",
       "      <td>2.024129</td>\n",
       "      <td>0.386542</td>\n",
       "      <td>1.104493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>0.052274</td>\n",
       "      <td>-1.736558</td>\n",
       "      <td>-0.263699</td>\n",
       "      <td>-0.219329</td>\n",
       "      <td>8.918393</td>\n",
       "      <td>-1.258320</td>\n",
       "      <td>-3.361146</td>\n",
       "      <td>0.893366</td>\n",
       "      <td>-0.631669</td>\n",
       "      <td>1.887286</td>\n",
       "      <td>...</td>\n",
       "      <td>2.117847</td>\n",
       "      <td>-1.050824</td>\n",
       "      <td>0.182872</td>\n",
       "      <td>0.242725</td>\n",
       "      <td>0.670161</td>\n",
       "      <td>0.112752</td>\n",
       "      <td>-3.006949</td>\n",
       "      <td>1.179606</td>\n",
       "      <td>1.156340</td>\n",
       "      <td>-1.218561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>1.443659</td>\n",
       "      <td>0.651892</td>\n",
       "      <td>0.550724</td>\n",
       "      <td>-1.146664</td>\n",
       "      <td>2.621641</td>\n",
       "      <td>-0.867143</td>\n",
       "      <td>0.312742</td>\n",
       "      <td>1.078004</td>\n",
       "      <td>-1.212524</td>\n",
       "      <td>-0.028143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631480</td>\n",
       "      <td>1.186236</td>\n",
       "      <td>-1.098508</td>\n",
       "      <td>1.159658</td>\n",
       "      <td>-1.957241</td>\n",
       "      <td>0.482533</td>\n",
       "      <td>3.777669</td>\n",
       "      <td>-0.424954</td>\n",
       "      <td>1.333374</td>\n",
       "      <td>2.325271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>-0.429145</td>\n",
       "      <td>-0.110821</td>\n",
       "      <td>1.257230</td>\n",
       "      <td>-0.088150</td>\n",
       "      <td>-3.925020</td>\n",
       "      <td>-0.251062</td>\n",
       "      <td>-2.212032</td>\n",
       "      <td>-2.692121</td>\n",
       "      <td>-0.005468</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384256</td>\n",
       "      <td>0.520610</td>\n",
       "      <td>1.594873</td>\n",
       "      <td>-0.352201</td>\n",
       "      <td>0.152333</td>\n",
       "      <td>-1.772249</td>\n",
       "      <td>0.758809</td>\n",
       "      <td>0.617485</td>\n",
       "      <td>1.464438</td>\n",
       "      <td>3.301445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8999 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.374101  0.537669  0.081063  0.756773  0.915231  2.557282  3.703187   \n",
       "1    -0.088370  0.154743  0.380716 -1.176126  1.699867 -0.258627 -1.384999   \n",
       "2    -0.685635  0.501283  1.873375  0.215224 -3.983468 -0.103637  4.136113   \n",
       "3     0.350867  0.721897 -0.477104 -1.748776 -2.627405  1.075433  4.954253   \n",
       "4    -0.424627  1.536196 -1.037752 -0.156466 -2.945038 -0.471607  3.494966   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8994  0.171644 -0.806952 -2.045671  0.021156  2.258491  0.429469  0.857187   \n",
       "8995  1.168564 -0.911253  1.685492  0.867183  3.606170 -0.673875 -1.889365   \n",
       "8996  0.052274 -1.736558 -0.263699 -0.219329  8.918393 -1.258320 -3.361146   \n",
       "8997  1.443659  0.651892  0.550724 -1.146664  2.621641 -0.867143  0.312742   \n",
       "8998 -0.429145 -0.110821  1.257230 -0.088150 -3.925020 -0.251062 -2.212032   \n",
       "\n",
       "            7         8         9   ...        30        31        32  \\\n",
       "0     1.673835 -0.764122 -1.228040  ... -0.969463  0.574154 -2.200519   \n",
       "1     1.093584  1.596633  0.230631  ... -0.769885 -0.005143  1.467490   \n",
       "2    -0.225431 -1.515015 -1.071763  ...  0.968609  2.386412 -0.131219   \n",
       "3    -3.293501 -0.760369  0.204360  ...  0.260553 -2.045650 -2.173227   \n",
       "4    -2.763629  0.819540  0.209529  ... -0.727066 -0.809620  4.504230   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "8994  0.972600  1.707492  1.676370  ... -1.366312  0.276543 -0.732764   \n",
       "8995  0.411385 -0.206817 -0.705771  ...  0.557757  0.379841 -1.474198   \n",
       "8996  0.893366 -0.631669  1.887286  ...  2.117847 -1.050824  0.182872   \n",
       "8997  1.078004 -1.212524 -0.028143  ...  0.631480  1.186236 -1.098508   \n",
       "8998 -2.692121 -0.005468  0.186300  ...  0.384256  0.520610  1.594873   \n",
       "\n",
       "            33        34        35        36        37        38        39  \n",
       "0    -1.612240  0.179031 -2.924596  0.643610 -1.470939 -0.067408 -0.976265  \n",
       "1     0.483803 -3.542981  0.814561 -1.652948  1.265866 -1.749248  1.773784  \n",
       "2     0.285646  2.302069  1.255588 -1.563090 -0.125258 -1.030761 -2.945329  \n",
       "3     0.372992  0.450700 -0.211657  1.301359 -0.522164  2.484883  0.039213  \n",
       "4    -0.481077 -2.923646 -0.468034 -0.846214  1.197350 -5.615563  2.049134  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "8994  0.243930 -1.151233 -0.274298  0.573013  1.109814 -1.905965  1.457601  \n",
       "8995 -0.322943  1.964519  0.122384  0.678023  2.024129  0.386542  1.104493  \n",
       "8996  0.242725  0.670161  0.112752 -3.006949  1.179606  1.156340 -1.218561  \n",
       "8997  1.159658 -1.957241  0.482533  3.777669 -0.424954  1.333374  2.325271  \n",
       "8998 -0.352201  0.152333 -1.772249  0.758809  0.617485  1.464438  3.301445  \n",
       "\n",
       "[8999 rows x 40 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "      <td>8999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.011503</td>\n",
       "      <td>0.004289</td>\n",
       "      <td>-0.001648</td>\n",
       "      <td>0.008587</td>\n",
       "      <td>1.262375</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>0.480785</td>\n",
       "      <td>-0.017627</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>-0.006567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018887</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>-0.476762</td>\n",
       "      <td>0.016230</td>\n",
       "      <td>-0.508743</td>\n",
       "      <td>-0.002221</td>\n",
       "      <td>0.451227</td>\n",
       "      <td>-0.002043</td>\n",
       "      <td>-1.003323</td>\n",
       "      <td>0.539619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.009140</td>\n",
       "      <td>1.011485</td>\n",
       "      <td>0.996724</td>\n",
       "      <td>0.989061</td>\n",
       "      <td>4.527741</td>\n",
       "      <td>0.999678</td>\n",
       "      <td>2.102425</td>\n",
       "      <td>2.204470</td>\n",
       "      <td>0.989236</td>\n",
       "      <td>0.991582</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003503</td>\n",
       "      <td>1.003379</td>\n",
       "      <td>2.202605</td>\n",
       "      <td>1.015822</td>\n",
       "      <td>2.097563</td>\n",
       "      <td>1.008446</td>\n",
       "      <td>2.187799</td>\n",
       "      <td>1.000207</td>\n",
       "      <td>1.979730</td>\n",
       "      <td>2.011614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.568633</td>\n",
       "      <td>-4.238067</td>\n",
       "      <td>-3.587473</td>\n",
       "      <td>-3.646144</td>\n",
       "      <td>-17.296514</td>\n",
       "      <td>-3.500646</td>\n",
       "      <td>-9.157707</td>\n",
       "      <td>-7.867021</td>\n",
       "      <td>-4.037177</td>\n",
       "      <td>-3.666707</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.545617</td>\n",
       "      <td>-3.914329</td>\n",
       "      <td>-8.510309</td>\n",
       "      <td>-4.702577</td>\n",
       "      <td>-8.860839</td>\n",
       "      <td>-3.579675</td>\n",
       "      <td>-9.034930</td>\n",
       "      <td>-3.820679</td>\n",
       "      <td>-8.174851</td>\n",
       "      <td>-7.945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.669906</td>\n",
       "      <td>-0.678960</td>\n",
       "      <td>-0.665481</td>\n",
       "      <td>-0.662634</td>\n",
       "      <td>-1.669568</td>\n",
       "      <td>-0.688873</td>\n",
       "      <td>-0.893890</td>\n",
       "      <td>-1.521886</td>\n",
       "      <td>-0.654016</td>\n",
       "      <td>-0.665386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.689295</td>\n",
       "      <td>-0.664589</td>\n",
       "      <td>-1.986448</td>\n",
       "      <td>-0.674016</td>\n",
       "      <td>-1.908508</td>\n",
       "      <td>-0.689390</td>\n",
       "      <td>-1.071141</td>\n",
       "      <td>-0.667375</td>\n",
       "      <td>-2.293528</td>\n",
       "      <td>-0.717607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.006067</td>\n",
       "      <td>0.010854</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>1.123602</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>0.534789</td>\n",
       "      <td>-0.022683</td>\n",
       "      <td>-0.006204</td>\n",
       "      <td>-0.005404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033899</td>\n",
       "      <td>-0.003129</td>\n",
       "      <td>-0.459178</td>\n",
       "      <td>0.013497</td>\n",
       "      <td>-0.481734</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.419180</td>\n",
       "      <td>-0.003718</td>\n",
       "      <td>-1.004709</td>\n",
       "      <td>0.636656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.703067</td>\n",
       "      <td>0.684773</td>\n",
       "      <td>0.658238</td>\n",
       "      <td>0.683597</td>\n",
       "      <td>4.002419</td>\n",
       "      <td>0.691098</td>\n",
       "      <td>1.891266</td>\n",
       "      <td>1.459877</td>\n",
       "      <td>0.676689</td>\n",
       "      <td>0.654391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655875</td>\n",
       "      <td>0.682256</td>\n",
       "      <td>1.026234</td>\n",
       "      <td>0.691870</td>\n",
       "      <td>0.957404</td>\n",
       "      <td>0.666468</td>\n",
       "      <td>1.938530</td>\n",
       "      <td>0.667712</td>\n",
       "      <td>0.321610</td>\n",
       "      <td>1.897022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.843549</td>\n",
       "      <td>3.538868</td>\n",
       "      <td>3.716102</td>\n",
       "      <td>3.667817</td>\n",
       "      <td>20.551947</td>\n",
       "      <td>4.565496</td>\n",
       "      <td>7.882210</td>\n",
       "      <td>7.391208</td>\n",
       "      <td>3.706671</td>\n",
       "      <td>3.322649</td>\n",
       "      <td>...</td>\n",
       "      <td>3.624639</td>\n",
       "      <td>4.251316</td>\n",
       "      <td>8.598575</td>\n",
       "      <td>4.157051</td>\n",
       "      <td>6.851583</td>\n",
       "      <td>3.911722</td>\n",
       "      <td>8.624332</td>\n",
       "      <td>3.860112</td>\n",
       "      <td>7.125848</td>\n",
       "      <td>9.464492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  8999.000000  8999.000000  8999.000000  8999.000000  8999.000000   \n",
       "mean      0.011503     0.004289    -0.001648     0.008587     1.262375   \n",
       "std       1.009140     1.011485     0.996724     0.989061     4.527741   \n",
       "min      -3.568633    -4.238067    -3.587473    -3.646144   -17.296514   \n",
       "25%      -0.669906    -0.678960    -0.665481    -0.662634    -1.669568   \n",
       "50%       0.006067     0.010854     0.007398     0.008996     1.123602   \n",
       "75%       0.703067     0.684773     0.658238     0.683597     4.002419   \n",
       "max       3.843549     3.538868     3.716102     3.667817    20.551947   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  8999.000000  8999.000000  8999.000000  8999.000000  8999.000000  ...   \n",
       "mean      0.006007     0.480785    -0.017627     0.006958    -0.006567  ...   \n",
       "std       0.999678     2.102425     2.204470     0.989236     0.991582  ...   \n",
       "min      -3.500646    -9.157707    -7.867021    -4.037177    -3.666707  ...   \n",
       "25%      -0.688873    -0.893890    -1.521886    -0.654016    -0.665386  ...   \n",
       "50%       0.011503     0.534789    -0.022683    -0.006204    -0.005404  ...   \n",
       "75%       0.691098     1.891266     1.459877     0.676689     0.654391  ...   \n",
       "max       4.565496     7.882210     7.391208     3.706671     3.322649  ...   \n",
       "\n",
       "                30           31           32           33           34  \\\n",
       "count  8999.000000  8999.000000  8999.000000  8999.000000  8999.000000   \n",
       "mean     -0.018887     0.007308    -0.476762     0.016230    -0.508743   \n",
       "std       1.003503     1.003379     2.202605     1.015822     2.097563   \n",
       "min      -4.545617    -3.914329    -8.510309    -4.702577    -8.860839   \n",
       "25%      -0.689295    -0.664589    -1.986448    -0.674016    -1.908508   \n",
       "50%      -0.033899    -0.003129    -0.459178     0.013497    -0.481734   \n",
       "75%       0.655875     0.682256     1.026234     0.691870     0.957404   \n",
       "max       3.624639     4.251316     8.598575     4.157051     6.851583   \n",
       "\n",
       "                35           36           37           38           39  \n",
       "count  8999.000000  8999.000000  8999.000000  8999.000000  8999.000000  \n",
       "mean     -0.002221     0.451227    -0.002043    -1.003323     0.539619  \n",
       "std       1.008446     2.187799     1.000207     1.979730     2.011614  \n",
       "min      -3.579675    -9.034930    -3.820679    -8.174851    -7.945400  \n",
       "25%      -0.689390    -1.071141    -0.667375    -2.293528    -0.717607  \n",
       "50%       0.000066     0.419180    -0.003718    -1.004709     0.636656  \n",
       "75%       0.666468     1.938530     0.667712     0.321610     1.897022  \n",
       "max       3.911722     8.624332     3.860112     7.125848     9.464492  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()\n",
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Data columns (total 40 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       999 non-null    float64\n",
      " 1   1       999 non-null    float64\n",
      " 2   2       999 non-null    float64\n",
      " 3   3       999 non-null    float64\n",
      " 4   4       999 non-null    float64\n",
      " 5   5       999 non-null    float64\n",
      " 6   6       999 non-null    float64\n",
      " 7   7       999 non-null    float64\n",
      " 8   8       999 non-null    float64\n",
      " 9   9       999 non-null    float64\n",
      " 10  10      999 non-null    float64\n",
      " 11  11      999 non-null    float64\n",
      " 12  12      999 non-null    float64\n",
      " 13  13      999 non-null    float64\n",
      " 14  14      999 non-null    float64\n",
      " 15  15      999 non-null    float64\n",
      " 16  16      999 non-null    float64\n",
      " 17  17      999 non-null    float64\n",
      " 18  18      999 non-null    float64\n",
      " 19  19      999 non-null    float64\n",
      " 20  20      999 non-null    float64\n",
      " 21  21      999 non-null    float64\n",
      " 22  22      999 non-null    float64\n",
      " 23  23      999 non-null    float64\n",
      " 24  24      999 non-null    float64\n",
      " 25  25      999 non-null    float64\n",
      " 26  26      999 non-null    float64\n",
      " 27  27      999 non-null    float64\n",
      " 28  28      999 non-null    float64\n",
      " 29  29      999 non-null    float64\n",
      " 30  30      999 non-null    float64\n",
      " 31  31      999 non-null    float64\n",
      " 32  32      999 non-null    float64\n",
      " 33  33      999 non-null    float64\n",
      " 34  34      999 non-null    float64\n",
      " 35  35      999 non-null    float64\n",
      " 36  36      999 non-null    float64\n",
      " 37  37      999 non-null    float64\n",
      " 38  38      999 non-null    float64\n",
      " 39  39      999 non-null    float64\n",
      "dtypes: float64(40)\n",
      "memory usage: 312.3 KB\n",
      "test info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8999 entries, 0 to 8998\n",
      "Data columns (total 40 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       8999 non-null   float64\n",
      " 1   1       8999 non-null   float64\n",
      " 2   2       8999 non-null   float64\n",
      " 3   3       8999 non-null   float64\n",
      " 4   4       8999 non-null   float64\n",
      " 5   5       8999 non-null   float64\n",
      " 6   6       8999 non-null   float64\n",
      " 7   7       8999 non-null   float64\n",
      " 8   8       8999 non-null   float64\n",
      " 9   9       8999 non-null   float64\n",
      " 10  10      8999 non-null   float64\n",
      " 11  11      8999 non-null   float64\n",
      " 12  12      8999 non-null   float64\n",
      " 13  13      8999 non-null   float64\n",
      " 14  14      8999 non-null   float64\n",
      " 15  15      8999 non-null   float64\n",
      " 16  16      8999 non-null   float64\n",
      " 17  17      8999 non-null   float64\n",
      " 18  18      8999 non-null   float64\n",
      " 19  19      8999 non-null   float64\n",
      " 20  20      8999 non-null   float64\n",
      " 21  21      8999 non-null   float64\n",
      " 22  22      8999 non-null   float64\n",
      " 23  23      8999 non-null   float64\n",
      " 24  24      8999 non-null   float64\n",
      " 25  25      8999 non-null   float64\n",
      " 26  26      8999 non-null   float64\n",
      " 27  27      8999 non-null   float64\n",
      " 28  28      8999 non-null   float64\n",
      " 29  29      8999 non-null   float64\n",
      " 30  30      8999 non-null   float64\n",
      " 31  31      8999 non-null   float64\n",
      " 32  32      8999 non-null   float64\n",
      " 33  33      8999 non-null   float64\n",
      " 34  34      8999 non-null   float64\n",
      " 35  35      8999 non-null   float64\n",
      " 36  36      8999 non-null   float64\n",
      " 37  37      8999 non-null   float64\n",
      " 38  38      8999 non-null   float64\n",
      " 39  39      8999 non-null   float64\n",
      "dtypes: float64(40)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"train info\")\n",
    "train_df.info()\n",
    "print(\"test info\")\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\n",
       "1    509\n",
       "0    490\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_df, train_labels_df, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train dimension :  (799, 40)\n",
      "x test dimension :  (200, 40)\n",
      "y train dimension :  (799, 1)\n",
      "y test dimension :  (200, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x train dimension : \",x_train.shape)\n",
    "print(\"x test dimension : \",x_test.shape)\n",
    "print(\"y train dimension : \",y_train.shape)\n",
    "print(\"y test dimension : \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalisation and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler()\n",
    "normalized_train_x = normalizer.fit_transform(x_train)\n",
    "normalized_test_x = normalizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_train_x = scaler.fit_transform(x_train)\n",
    "scaled_test_x = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As there is no null values present in test and train data therefore there is not need of any Data pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Logistic Regression Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(x_train,y_train)\n",
    "y_predLR = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_predLR)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(normalized_train_x,y_train)\n",
    "y_predNLR = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_predNLR)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(scaled_train_x,y_train)\n",
    "y_predSLR = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_predSLR)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.5 %\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeClassifier(criterion=\"gini\",random_state = 42) \n",
    "clf.fit(x_train, y_train)\n",
    "y_predDT=clf.predict(x_test)\n",
    "print(accuracy_score(y_test,y_predDT)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.0 %\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeClassifier(criterion=\"gini\",random_state = 42) \n",
    "clf.fit(normalized_train_x, y_train)\n",
    "y_predDT=clf.predict(x_test)\n",
    "print(accuracy_score(y_test,y_predDT)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.5 %\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeClassifier(criterion=\"gini\",random_state = 42) \n",
    "clf.fit(scaled_train_x, y_train)\n",
    "y_predDT=clf.predict(x_test)\n",
    "print(accuracy_score(y_test,y_predDT)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "svclassifier=SVC(kernel='rbf',random_state=30, gamma='auto')\n",
    "svclassifier.fit(x_train,y_train)\n",
    "y_predSVM=svclassifier.predict(x_test)\n",
    "svclassifier.score(X_test, y_test)\n",
    "print(accuracy_score(y_test, y_predSVM)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "svclassifier=SVC(kernel='rbf',random_state=30, gamma='auto')\n",
    "svclassifier.fit(normalized_train_x,y_train)\n",
    "y_predNSVM=svclassifier.predict(x_test)\n",
    "svclassifier.score(x_test, y_test)\n",
    "print(accuracy_score(y_test, y_predNSVM)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardrized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "svclassifier=SVC(kernel='rbf',random_state=30, gamma='auto')\n",
    "svclassifier.fit(scaled_train_x,y_train)\n",
    "y_predSSVM=svclassifier.predict(x_test)\n",
    "svclassifier.score(x_test, y_test)\n",
    "print(accuracy_score(y_test, y_predSSVM)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.0 %\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7).fit(x_train, y_train.values.ravel())\n",
    "pred_KNN = knn.predict(x_test)\n",
    "print(accuracy_score(y_test, pred_KNN)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.5 %\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7).fit(normalized_train_x, y_train.values.ravel())\n",
    "pred_NKNN = knn.predict(x_test)\n",
    "print(accuracy_score(y_test, pred_NKNN)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.0 %\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7).fit(scaled_train_x, y_train.values.ravel())\n",
    "pred_SKNN = knn.predict(x_test)\n",
    "print(accuracy_score(y_test, pred_KNN)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.5 %\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(criterion='gini',n_estimators=75,random_state =42)\n",
    "RF.fit(x_train, y_train.values.ravel())\n",
    "pred_RF = RF.predict(x_test)\n",
    "print(accuracy_score(pred_RF,y_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.0 %\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(criterion='gini',n_estimators=75,random_state =42)\n",
    "RF.fit(normalized_train_x, y_train.values.ravel())\n",
    "pred_NRF = RF.predict(x_test)\n",
    "print(accuracy_score(pred_NRF,y_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardrized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.0 %\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(criterion='gini',n_estimators=75,random_state =42)\n",
    "RF.fit(scaled_train_x, y_train.values.ravel())\n",
    "pred_SRF = RF.predict(x_test)\n",
    "print(accuracy_score(pred_SRF,y_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As KNN classifier gives an accuracy of 86% therefore i am applying KNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefict  = knn.predict(test_df)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
